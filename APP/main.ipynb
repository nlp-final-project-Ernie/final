{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 具体应用：用Paddlepaddle做一个服装广告文案生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 安装相关库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n",
      "PaddlePaddle works well on 1 GPU.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"
     ]
    }
   ],
   "source": [
    "# 检查paddlepaddle是否可以使用GPU\n",
    "import paddle\n",
    "paddle.utils.run_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照数据集要求对其进行整理，格式为“序号\\t输入文本\\t标签”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "Keys = df[\"关键词\"].values\n",
    "Txts = df[\"文案\"].values\n",
    "\n",
    "with open(\"format_data.txt\", \"w\",encoding='utf-8') as f:\n",
    "    for i, k in enumerate(Keys):\n",
    "        t = Txts[i]\n",
    "        f.write(\"{}\\t{}\\t{}\\n\".format(i, k, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 调用Paddlehub模型进行预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型我们选用ERNIE-GEN模型\n",
    "\n",
    "论文地址：https://arxiv.org/abs/2001.11314\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9698f8fef8004f579d01ca0d4a8a8255d58a8cc895c44d59b97141c82a23b833)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "E:\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\u001b[32m[2023-12-30 06:54:48,915] [    INFO]\u001b[0m - Already cached C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:48,935] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:48,936] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:48,962] [    INFO]\u001b[0m - Already cached C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\ernie_v1_chn_base.pdparams\u001b[0m\n",
      "\u001b[35m[2023-12-30 06:54:48,968] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:49,378] [    INFO]\u001b[0m - loading pretrained model from C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\ernie_v1_chn_base.pdparams\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:50,028] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:50,038] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:50,038] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:50,038] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:54:50,038] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
      "E:\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:2293: FutureWarning: The `max_seq_len` argument is deprecated and will be removed in a future version, please use `max_length` instead.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\paddlenlp\\transformers\\tokenizer_utils_base.py:1865: UserWarning: Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  warnings.warn(\n",
      "\u001b[32m[2023-12-30 06:55:26,638] [    INFO]\u001b[0m - [step 100 / 2000]train loss 10.55602, ppl 38407.76562, elr 2.500e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:55:59,263] [    INFO]\u001b[0m - [step 200 / 2000]train loss 6.86149, ppl 954.78381, elr 5.000e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:56:31,988] [    INFO]\u001b[0m - [step 300 / 2000]train loss 4.59936, ppl 99.42072, elr 4.722e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:57:04,808] [    INFO]\u001b[0m - [step 400 / 2000]train loss 4.31124, ppl 74.53319, elr 4.444e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:57:04,818] [    INFO]\u001b[0m - save the model in nlg_param\\step_400_ppl_74.53319.params\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:57:40,347] [    INFO]\u001b[0m - [step 500 / 2000]train loss 3.66294, ppl 38.97569, elr 4.167e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:58:13,218] [    INFO]\u001b[0m - [step 600 / 2000]train loss 3.24425, ppl 25.64245, elr 3.889e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:58:46,108] [    INFO]\u001b[0m - [step 700 / 2000]train loss 3.14530, ppl 23.22666, elr 3.611e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:59:19,038] [    INFO]\u001b[0m - [step 800 / 2000]train loss 2.74581, ppl 15.57721, elr 3.333e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:59:19,038] [    INFO]\u001b[0m - save the model in nlg_param\\step_800_ppl_15.57721.params\u001b[0m\n",
      "\u001b[32m[2023-12-30 06:59:55,442] [    INFO]\u001b[0m - [step 900 / 2000]train loss 2.74978, ppl 15.63926, elr 3.056e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:00:28,311] [    INFO]\u001b[0m - [step 1000 / 2000]train loss 2.73150, ppl 15.35586, elr 2.778e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:01:01,248] [    INFO]\u001b[0m - [step 1100 / 2000]train loss 2.70404, ppl 14.93996, elr 2.500e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:01:34,668] [    INFO]\u001b[0m - [step 1200 / 2000]train loss 2.62232, ppl 13.76760, elr 2.222e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:01:34,673] [    INFO]\u001b[0m - save the model in nlg_param\\step_1200_ppl_13.76760.params\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:02:10,613] [    INFO]\u001b[0m - [step 1300 / 2000]train loss 2.23419, ppl 9.33889, elr 1.944e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:02:44,683] [    INFO]\u001b[0m - [step 1400 / 2000]train loss 2.82640, ppl 16.88456, elr 1.667e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:03:18,553] [    INFO]\u001b[0m - [step 1500 / 2000]train loss 2.39898, ppl 11.01190, elr 1.389e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:03:52,346] [    INFO]\u001b[0m - [step 1600 / 2000]train loss 2.46037, ppl 11.70910, elr 1.111e-05\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:03:52,348] [    INFO]\u001b[0m - save the model in nlg_param\\step_1600_ppl_11.70910.params\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:04:28,364] [    INFO]\u001b[0m - [step 1700 / 2000]train loss 2.55590, ppl 12.88293, elr 8.333e-06\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:05:02,968] [    INFO]\u001b[0m - [step 1800 / 2000]train loss 2.94100, ppl 18.93468, elr 5.556e-06\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:05:36,812] [    INFO]\u001b[0m - [step 1900 / 2000]train loss 2.70022, ppl 14.88307, elr 2.778e-06\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:11,269] [    INFO]\u001b[0m - [step 2000 / 2000]train loss 2.26135, ppl 9.59600, elr 0.000e+00\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:11,269] [    INFO]\u001b[0m - save the model in nlg_param\\step_2000_ppl_9.59600.params\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:13,084] [    INFO]\u001b[0m - Begin export the model save in nlg_param\\step_2000_ppl_9.59600.params ...\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:17,638] [    INFO]\u001b[0m - The module has exported to C:\\Users\\11409\\Documents\\nlp\\nlg\u001b[0m\n",
      "E:\\anaconda3\\envs\\paddle_env\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\u001b[32m[2023-12-30 07:06:34,492] [    INFO]\u001b[0m - Successfully installed nlg-1.0.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddlehub as hub\n",
    "\n",
    "module = hub.Module(name=\"ernie_gen\")\n",
    "\n",
    "result = module.finetune(\n",
    "    train_path='format_data.txt',\n",
    "    save_dir=\"nlg_param\",\n",
    "    max_steps=2000,\n",
    "    noise_prob=0.1,\n",
    "    save_interval=400,\n",
    "    max_encode_len=60,\n",
    "    max_decode_len=60\n",
    ")\n",
    "\n",
    "# 将训练参数打包为hub model\n",
    "module.export(params_path=result['last_save_path'], module_name=\"nlg\", author=\"etta\")\n",
    "!hub install nlg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 运行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-12-30 07:06:36,311] [    INFO]\u001b[0m - Already cached C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\ernie_v1_chn_base.pdparams\u001b[0m\n",
      "\u001b[35m[2023-12-30 07:06:36,311] [   DEBUG]\u001b[0m - init ErnieModel with config: {'attention_probs_dropout_prob': 0.1, 'hidden_act': 'relu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'max_position_embeddings': 513, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 18000, 'pad_token_id': 0}\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:36,638] [    INFO]\u001b[0m - loading pretrained model from C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\ernie_v1_chn_base.pdparams\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:37,147] [    INFO]\u001b[0m - param:mlm_bias not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:37,148] [    INFO]\u001b[0m - param:mlm.weight not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:37,148] [    INFO]\u001b[0m - param:mlm.bias not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:37,148] [    INFO]\u001b[0m - param:mlm_ln.weight not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:37,148] [    INFO]\u001b[0m - param:mlm_ln.bias not set in pretrained model, skip\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:38,435] [    INFO]\u001b[0m - Already cached C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:38,462] [    INFO]\u001b[0m - tokenizer config file saved in C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-12-30 07:06:38,464] [    INFO]\u001b[0m - Special tokens file saved in C:\\Users\\11409\\.paddlenlp\\models\\ernie-1.0\\special_tokens_map.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import paddlehub as hub\n",
    "\n",
    "module = hub.Module(directory=\"nlg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身显瘦\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感好，遮肉显瘦，修身的版型，遮肉显\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感好，遮肉显瘦，修身显瘦，修身显瘦\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身版型\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修饰身材\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感好，遮肉显瘦，修身显瘦，修身显腿\n",
      "这款连衣裙采用优质面料，质地轻盈，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身显瘦，修\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修饰身形\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感好，遮肉显瘦，修身的版型设计，上\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感好，遮肉显瘦，修身的版型设计，修\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"显瘦\"]\n",
    "results = module.generate(texts=test_texts, use_gpu=False, beam_width=10)\n",
    "for result in results[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身显瘦\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，手感顺滑，垂感好，垂感好，遮肉显瘦，修身显瘦\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修饰身材\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身版型\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，手感顺滑，垂感好，垂感好，遮肉显瘦，修饰身材\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"性感\"]\n",
    "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
    "for result in results[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身显瘦\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修饰身材\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身版型\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修身剪裁\n",
      "这款连衣裙采用优质面料，手感细腻顺滑，手感顺滑，垂感好，垂感好，垂感软糯，垂感好，遮肉显瘦，修饰腿部\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"复古\"]\n",
    "results = module.generate(texts=test_texts, use_gpu=False, beam_width=5)\n",
    "for result in results[0]:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 改进方向：\n",
    "\n",
    "可以看到数据集太少，出现了明显的过拟合现象，可以多搜集一些。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:paddle_env]",
   "language": "python",
   "name": "conda-env-paddle_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
